{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "**Note:** If you are using the workspace, you will need to go to the terminal and run the command `conda update pandas` before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.  \n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below.  First you need to access the terminal:\n",
    "\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "import seaborn as sns #For Data visualization\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df, new_col_names):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    ----------\n",
    "    df: input dataframe for renaming columns\n",
    "    new_col_names: define new column name for each column\n",
    "    \n",
    "    OUTPUT\n",
    "    -------\n",
    "    df: output data frame with renamed column names\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    df= df.rename(columns = new_col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename portfolio columns\n",
    "new_col_names_portfolio = {'difficulty':'offer_difficulty' , 'id':'offer_id', \n",
    "                 'duration':'offer_duration', 'reward': 'offer_reward'}\n",
    "portfolio  = rename_cols(portfolio, new_col_names_portfolio )\n",
    "\n",
    "#rename profile columns\n",
    "new_col_profile = {'id':'customer_id' , 'income':'customer_income'}\n",
    "profile = rename_cols(profile, new_col_profile )\n",
    "\n",
    "# Rename Transcript columns\n",
    "new_col_transcript = {'person': 'customer_id'}\n",
    "transcript = rename_cols(transcript, new_col_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_offertype(portfolio=portfolio):\n",
    "    '''\n",
    "    INPUT:\n",
    "    portfolio - (pandas dataframe), portfolio data\n",
    "    \n",
    "    OUTPUT:\n",
    "    portfolio - (pandas dataframe), cleaned portfolio data\n",
    "\n",
    "    \n",
    "    Description:\n",
    "    This function cleans the dat and provides a DatFrame with Offer ID and other data about the offer. \n",
    "    '''    \n",
    "    \n",
    "    # One hot encode the 'offertype' column\n",
    "    offertype = pd.get_dummies(portfolio['offer_type'])\n",
    "    \n",
    "    # One hot encode the 'channels' columns\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb_fit = mlb.fit(portfolio['channels'])\n",
    "    channels_df = pd.DataFrame(mlb_fit.transform(portfolio['channels']),columns=mlb_fit.classes_)\n",
    "    \n",
    "    #Drop the old 'channels' and 'offer_type' columns\n",
    "    portfolio = portfolio.drop(columns=['channels', 'offer_type'])\n",
    "    \n",
    "    #Replace the 'offertype' and 'channels' columns\n",
    "    portfolio = pd.concat([portfolio, offertype, channels_df], axis=1)\n",
    "    \n",
    "    \n",
    "    #Reorder the columns order\n",
    "    portfolio = portfolio[[ 'Offer_Id','offer_difficulty','offer_duration','offer_reward','bogo','discount',\n",
    "                            'informational','email','mobile','social','web']]\n",
    "\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7e8ac4bdd8>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e8ac4bd68>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find and visualize Missing Data\n",
    "\n",
    "\n",
    "sns.heatmap(profile.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n",
    "profile.isnull().sum(axis=0) * 100  / profile.shape[0]\n",
    "profile['age'].hist(bins = 25)\n",
    "# Remove customers with N/A income data\n",
    "profile = profile[profile['customer_income'].notnull()]\n",
    "profile['age'].hist(bins = 25)\n",
    "profile.isnull().sum(axis=0) * 100  / profile.shape[0]\n",
    "profile['customer_income'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_profile_final(profile = profile):\n",
    "    \n",
    "    #Removed those with no income data\n",
    "    profile = profile[profile['income'].notnull()]\n",
    "    \n",
    "    \n",
    "    #Removed customer with unspecified Gender\n",
    "    profile = profile[profile['gender'] != 'O']\n",
    "    profile = profile.reset_index(drop=True)\n",
    "    \n",
    "    binarizerobj = LabelBinarizer()\n",
    "    profile['gender'] = binarizerobj.fit_transform(profile['gender'])\n",
    "    \n",
    "    gender_integer_map = {}\n",
    "    for i in binarizerobj.classes_:\n",
    "        gender_integer_map[i] = binarizerobj.transform([i])[0,0]\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Change datetype of bacame_member_on column\n",
    "    profile['became_member_on'] = pd.to_datetime(profile['became_member_on'], format = '%Y%m%d')   \n",
    "    #Encode the year values\n",
    "    profile['membership_year'] = profile['became_member_on'].apply(lambda elem: elem.year)\n",
    "    membership_year_df = pd.get_dummies(profile['membership_year'])\n",
    "    \n",
    "    \n",
    "    #Group the age ranges\n",
    "    labels = ['Generation Z','Millennials', 'Generation X', 'Baby Boomers', 'The Silent Generation']\n",
    "    profile['age_group'] = pd.cut(profile['age'], bins=5, labels=labels)\n",
    "    # Encode for Age ranges\n",
    "    agerange_df = pd.get_dummies(profile['age_group'])\n",
    "    \n",
    "    # Appened all the encoded variables to the main dataframe\n",
    "    profile = pd.concat([profile,\n",
    "                         agerange_df,\n",
    "                         membership_year_df], axis=1)\n",
    "\n",
    "    # Drop depcreated columns\n",
    "    profile = profile.drop(columns=['age',\n",
    "                                    'age_group',\n",
    "                                    'became_member_on',\n",
    "                                    'membership_year'])    \n",
    "    return profile\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze transcript Dated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove customer id's that are not in the customer profile DataFrame\n",
    "select_data = transcript['customer_id'].isin(profile['customer_id'])\n",
    "transcript = transcript[select_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from hours to days\n",
    "transcript['time'] /= 24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change'person' column name to 'customer_id'\n",
    "transcript = transcript.rename(columns={'time': 'time_in_days'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offer = transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "offer['offerid'] =\\\n",
    "        offer['value'].apply(lambda elem: list(elem.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offer['event'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers = offer[offer['event'].isin(['offer received' , 'offer completed', 'offer viewed' ])].drop(['value'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transactions = offer[offer['event']=='transaction'].drop(['value'], axis =1)\n",
    "transactions = transactions.rename(columns={'offerid': 'amount'})\n",
    "transactions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode customer offer events\n",
    "event_df = pd.get_dummies(offers['event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    offers = pd.concat([offers,event_df], axis =1)\n",
    "    offers = offers.drop(columns= ['event'])\n",
    "    offers  = offers.rename(columns={'offer completed': 'completed','offer received':'received' , 'offer viewed': 'viewed'})\n",
    "    offers = offers[['offerid','customer_id', 'time_in_days', 'completed',\n",
    "           'received', 'viewed']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcript(transcript = transcript):\n",
    "    \n",
    "    # Remove customer id's that are not in the customer profile DataFrame\n",
    "    select_data = transcript['customer_id'].isin(profile['customer_id'])\n",
    "    transcript = transcript[select_data]\n",
    "    \n",
    "    # Convert from hours to days\n",
    "    transcript['time'] /= 24.0    \n",
    "    \n",
    "    # Change'person' column name to 'customer_id'\n",
    "    transcript = transcript.rename(columns={'time': 'time_in_days'})\n",
    "    \n",
    "    transcript['offerid'] =\\\n",
    "        transcript['value'].apply(lambda elem: list(elem.values())[0])\n",
    "    \n",
    "    transcript = transcript[transcript['event'].isin(['offer received' , \n",
    "                                                      'offer completed', 'offer viewed' ])].drop(['value'], axis =1)\n",
    "    \n",
    "    \n",
    "    #Create seperate Dataframes for Offers and Transactions\n",
    "    \n",
    "    #1.Create Dataframe for Transactions\n",
    "    transactions = transcript[transcript['event']=='transaction'].drop(['value'], axis =1)\n",
    "    transactions = transactions.rename(columns={'offerid': 'amount'})\n",
    "    \n",
    "    \n",
    "    # One hot encode customer offer events\n",
    "    event_df = pd.get_dummies(transcript['event'])\n",
    "    \n",
    "    #2.Create Dataframe for offers\n",
    "    offers = pd.concat([transcript,event_df], axis =1)\n",
    "    offers = offers.drop(columns= ['event'])\n",
    "    offers  = offers.rename(columns={'offer completed': 'completed','offer received':'received' , 'offer viewed': 'viewed'})\n",
    "    offers = offers[['offerid','customer_id', 'time_in_days', 'completed',\n",
    "           'received', 'viewed']]\n",
    "    \n",
    "    return offers , transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['value'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-651afd460fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-202-384e27972631>\u001b[0m in \u001b[0;36mclean_transcript\u001b[0;34m(transcript)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#1.Create Dataframe for Transactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'transaction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'offerid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'amount'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['value'] not found in axis\""
     ]
    }
   ],
   "source": [
    "clean_transcript(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
